import multi_label_stratif
import numpy as np
import pandas as pd
import cPickle
import sys
import os
from scipy.io import savemat, loadmat


def read_grouping(groupID, fpath=os.curdir):
    """read grouping
    Args:
        groupID (int): the ID number for grouping to use
    Returns:
        grouping (dict): map from original instrument to corresponding group
    """
    instGrouping = pd.read_csv(os.path.join(fpath, 'instGroup.csv'))
    grouping = dict(zip(instGrouping['Instrument'].values,
                        instGrouping['Group {}'.format(groupID)].values))
    return grouping


def read_pkl_file(fname, fpath=os.curdir):
    """read pickle file
    """
    with open(os.path.join(fpath, fname), 'rb') as f:
        file_data = cPickle.load(f)
    return file_data


def read_txt_file(fname, fpath=os.curdir):
    """read text file generated by data_prep.py
    """
    with open(os.path.join(fpath, fname), 'rb') as f:
        file_data = f.read().strip().split('\n')
    return file_data


def replace_with_grouping(label_mapping, grouping):
    for k, v in label_mapping.items():
        label_mapping[k] = set([grouping[i] if i in grouping else i
                                for i in v])
    return label_mapping


def get_rare_instr(label_mapping, all_instruments, thres):
    """get a set of rare instruments
    Args:
        label_mapping (dict):
        all_instruments (list):
        thres (int): the number of appearance before which is considered rare
    Returns:
        rare_instr (set): set of rare instruments
    """
    cnt = {i: 0 for i in all_instruments}
    for k, v in label_mapping.items():
        for i in v:
            cnt[i] = cnt.get(i, 0) + 1
    rare_instr = set()
    for k, v in cnt.items():
        if v < thres:
            rare_instr.add(k)
    return rare_instr


def replace_rare(label_mapping, rare_instr):
    """raplace rare instruments with 'OTHER'
    """
    for k, v in label_mapping.items():
        label_mapping[k] = v - rare_instr
        if len(label_mapping[k]) < len(v):
            print '{} has rare item'.format(k)
            label_mapping[k].add('OTHER')


def do_split(X, label_mapping, kwargs):
    """Do the split with multi_label_stratif.py
    Args:
        X (list): list of song names
        label_mapping (dict):
        kwargs (dict): arguments to pass to multi_label_stratif
    Returns:
        datasets (list of list): each inner list contains song names
                                 corresponding dataset
    """
    y = [list(label_mapping[i]) for i in X]
    datasets_i = multi_label_stratif.multi_label_stratif(y, **kwargs)
    X = np.array(X, dtype=object)
    datasets = []
    for i in datasets_i:
        datasets.append(list(X[i]))
    return datasets


def get_instr_count(song_names, label_mapping):
    cnt = {}
    for i in song_names:
        for j in label_mapping[i]:
            cnt[j] = cnt.get(j, 0) + 1
    return cnt


def build_train_test_set(datasets, all_instruments, rare_instr):
    """Build training and test set files from data file for individual songs
    Args:
        datasets (list of list): each inner list contains song names
                                 corresponding dataset
    """
    # get indices for rare instruments
    rare_index = [i for i, e in enumerate(all_instruments) if e in rare_instr]
    nonrare_index = [i for i, e in enumerate(all_instruments)
                     if e not in rare_instr]
    print 'Number of nonrare instruments = {}'.format(len(nonrare_index))

    nonrare_instr = [i for i in all_instruments if i not in rare_instr]
    print 'Nonrare instruments are {}'.format(nonrare_instr)
    with open('nonrare_instr.txt', 'wb') as f:
        f.write('\n'.join(nonrare_instr))

    print '{} datasets to build'.format(len(datasets))

    for k, elm in enumerate(datasets):
        # initialize
        data = [[], [], [], [], []]

        # build test set
        for i in elm:
            data_read = loadmat('{}_patched.mat'.format(i))
            for j, e in enumerate(['X', 'y', 'present', 'song_name', 'time']):
                data[j].append(np.float32(data_read[e]))
            del data_read
        data = [np.vstack(i) for i in data]
        data = dict(zip(['X', 'y', 'p', 's', 't'],
                        data))
        # deal with OTHER instruments
        temp = data['y'][:, nonrare_index]
        data['y'] = np.hstack([temp, data['y'][:, rare_index].
                               max(1).reshape(len(temp), 1)])
        data['p'] = np.hstack([data['p'][:, nonrare_index],
                               np.zeros((len(temp), 1),
                                        dtype='float32')])
        print 'test set shape: {}'.format(data['y'].shape)
        savemat('dataset_{}.mat'.format(k), data)
        del data
        print 'finished building data set {}'.format(k)


def generate_split(groupID, rare_thres, songs_to_split=None, start_song=0,
                   end_song=122, fpath=os.curdir, **kwargs_split):
    """Do this split
    Args:
        groupID (int): group ID to use for grouping
        rare_thres (int): threshold below which is considered rare instrument
        songs_to_split (list): list of int, indexing song names in
                               song_name_list.txt generated by data_prep.py.
                               Must be None if start_song and end_song is used.
        start_song (int): The starting index for a contiguous subsequence of
                          song_name_list to use for split.
        end_song (int): The ending index for a contiguous subsequence of
                        song_name_list to use for split.
        fpath (str): the data path to operate on
        kwargs_split : extra args to pass to do_split
    """
    grouping = read_grouping(groupID, fpath)
    label_mapping = read_pkl_file('song_instr.pkl', fpath)
    song_name_list = read_txt_file('song_name_list.txt', fpath)
    all_instruments = read_txt_file('all_instruments.txt', fpath)
    if songs_to_split is not None:
        song_name_list = [song_name_list[i] for i in songs_to_split]
    else:
        song_name_list = song_name_list[start_song:end_song]

    # get label mapping for songs considered only
    label_mapping = {i: label_mapping[i] for i in song_name_list}

    label_mapping = replace_with_grouping(label_mapping, grouping)
    rare_instr = get_rare_instr(label_mapping, all_instruments, rare_thres)
    replace_rare(label_mapping, rare_instr)
    datasets = do_split(song_name_list, label_mapping, kwargs_split)
    for idx, e in enumerate(datasets):
        with open('dataset_{}_songs.txt'.format(idx), 'wb') as f:
            f.write('\n'.join(e))
        dataset_cnt = [str(i) for i in
                       get_instr_count(e, label_mapping).items()]
        with open('dataset_{}_instr_distr.txt'.format(idx), 'wb') as f:
            f.write('\n'.join(dataset_cnt))
    build_train_test_set(datasets, all_instruments, rare_instr)


def main():
    generate_split(4, 20, num_split=5, p_split=[0.2, 0.2, 0.2, 0.2, 0.2],
                   rand_state=2345)
